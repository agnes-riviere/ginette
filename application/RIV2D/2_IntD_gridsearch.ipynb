{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b982015",
   "metadata": {},
   "source": [
    "Probabilistic inversion is a technique used to estimate unknown parameters of a physical model by incorporating the uncertainty present in both the data and the model itself. Unlike deterministic methods, which yield a single \"best-fit\" solution, probabilistic inversion provides a probability distribution for each parameter, reflecting the range and likelihood of possible values.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "- **Uncertainty:** Real-world measurements and models are never perfect. Probabilistic inversion explicitly accounts for these uncertainties, leading to more robust and informative results.\n",
    "- **Parameter Estimation:** Instead of finding just one set of parameters, we estimate how likely different parameter values are, given the observed data.\n",
    "- **Probability Distribution:** The result is not a single answer, but a distribution that shows which parameter values are more or less probable.\n",
    "\n",
    "## Grid Search Approach\n",
    "\n",
    "Grid search is a straightforward way to perform probabilistic inversion:\n",
    "\n",
    "1. **Define Parameter Ranges:** Choose the parameters to estimate and specify the range and step size for each.\n",
    "2. **Generate Parameter Combinations:** Create a grid of all possible combinations of parameter values.\n",
    "3. **Simulate and Compare:** For each combination, run the model and compare its output to the observed data.\n",
    "4. **Compute Likelihood:** Calculate how well each parameter set matches the data (e.g., using mean squared error or another criterion).\n",
    "5. **Build Probability Distributions:** Assign probabilities to each parameter set based on their likelihood, resulting in a probability distribution over the parameter space.\n",
    "\n",
    "## Marginal Distributions\n",
    "\n",
    "- **1D Marginal Distribution:** Shows the probability distribution of a single parameter, integrating (summing) over all other parameters. This helps you understand the uncertainty and most likely values for each parameter individually.\n",
    "- **2D Marginal Distribution:** Shows the joint probability distribution for two parameters at a time, revealing possible correlations or dependencies between them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366ae648",
   "metadata": {},
   "source": [
    "### Step-by-Step Explanation of the Code Workflow\n",
    "\n",
    "This notebook guides you through a **probabilistic inversion** using a grid search approach for the \"IntD\" station. Here’s what each part does, explained simply:\n",
    "\n",
    "1. **Setup and Imports**  \n",
    "    - The code imports all the necessary Python libraries and custom functions.\n",
    "    - It sets up paths and directories needed for the simulation.\n",
    "\n",
    "2. **Loading Observed Data**  \n",
    "    - The observed temperature data (`obs_temp`) is loaded from a CSV file.\n",
    "    - The code makes sure all temperature and time columns are in the correct format for analysis.\n",
    "\n",
    "3. **Preparing Simulation Folders**  \n",
    "    - The script creates folders to organize simulation results, outputs, and parameters.\n",
    "    - It also compiles the simulation code if needed.\n",
    "\n",
    "4. **Defining Parameters for Grid Search**  \n",
    "    - You specify which zones and parameters you want to estimate (invert).\n",
    "    - The code sets the range of values for each parameter in each zone.\n",
    "    - It then creates a table (`param_table`) with all possible combinations of these parameter values.\n",
    "\n",
    "5. **Saving Parameter Table and Inputs**  \n",
    "    - The parameter combinations are saved to a file for later use.\n",
    "    - Another file (`input_inversion.txt`) is created to store all important settings for the inversion.\n",
    "\n",
    "6. **Running Simulations**  \n",
    "    - The script loops through each set of parameters, runs the simulation, and saves the results.\n",
    "    - All simulation results are saved for further analysis.\n",
    "\n",
    "**Key Variables to Remember:**\n",
    "- `Station`: The name of the station being analyzed (here, \"IntD\").\n",
    "- `obs_temp`: The DataFrame containing observed temperature data.\n",
    "- `sensors`: List of sensor names used for temperature measurements.\n",
    "- `zones_to_invert`, `parameters_to_invert`, `param_ranges`: Define which parameters are estimated and their ranges.\n",
    "- `param_table`: Table with all parameter combinations for the grid search.\n",
    "\n",
    "**In summary:**  \n",
    "You are systematically testing many combinations of model parameters to see which ones best match the observed temperature data, while keeping everything organized and reproducible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df479296",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f \n",
    "Station=\"IntD\"\n",
    "# This script is used to generate a grid search for the IntD station\n",
    "# name file Station+grid_search.py\n",
    "name_file = Station + \"_grid_search.py\"\n",
    "with open(name_file, \"w\") as f:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea4915ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.src_python.Grid_search' from '/home/ariviere/Programmes/ginette/src/src_python/Grid_search.py'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Created on Wed Oct 18 14:57:23 2023\n",
    "import functions mesh\n",
    "\"\"\"\n",
    "dir_ginette = \"/home/ariviere/Programmes/ginette\"\n",
    "# RIV2D + Station\n",
    "\n",
    "import os\n",
    "main_dir = os.path.join(dir_ginette, \"application/RIV2D\", Station)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "# Ajouter le chemin du dossier src au PYTHONPATH\n",
    "import importlib\n",
    "sys.path.append(dir_ginette)  # Ajouter le dossier parent de src\n",
    "\n",
    "# use __init__.py to import all functions/ in src/src_gmsh and src/src_pythont\n",
    "# insure \n",
    "from src.src_gmsh import mesh_generator\n",
    "from src.src_python import Init_folders\n",
    "from src.src_python import Direct_model\n",
    "from src.src_python import Read_obs\n",
    "from src.src_python import Plot\n",
    "from src.src_python import stat_critere\n",
    "from src.src_python import Grid_search\n",
    "\n",
    "# Import all functions/classes from the relevant modules\n",
    "from src.src_gmsh.mesh_generator import *\n",
    "from src.src_python.Init_folders import *\n",
    "from src.src_python.Direct_model import *\n",
    "from src.src_python.Read_obs import *\n",
    "from src.src_python.Plot import *\n",
    "from src.src_python.stat_critere import *\n",
    "from src.src_python.Grid_search import *\n",
    "import importlib\n",
    "\n",
    "\n",
    "importlib.reload(Init_folders)\n",
    "importlib.reload(Direct_model)\n",
    "importlib.reload(Grid_search)\n",
    "\n",
    "# give me all names of the functions in Init_folders\n",
    "#print(Init_folders.__dict__)\n",
    "#print([name for name in dir(Init_folders) if callable(getattr(Init_folders, name)) and not name.startswith(\"__\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d732f50",
   "metadata": {},
   "source": [
    "```markdown\n",
    "### Date, observation data, sensor name,....\n",
    "\n",
    "1. **Reload the Grid_search Module:**  \n",
    "    If you made change_s to the `Grid_search` code, this line makes sure Python uses the newest version.  \n",
    "    `importlib.reload_(Grid_search)`\n",
    "\n",
    "2. **Set the Simulation Start Date:**  \n",
    "    The simulation will start at noon on September 19, 2016.  \n",
    "    `date_simul_bg = pd.to_datetime(\"2016/09/19 12:00:00\")`\n",
    "\n",
    "3. **Station Name:**  \n",
    "    The variable `Station` is already set to `\"IntD\"`. This tells the code which station's data to use.\n",
    "\n",
    "4. **List of Sensors:**  \n",
    "    The code will use 8 temperature sensors, named `\"Temp_1\"` to `\"Temp_8\"`.\n",
    "\n",
    "5. **Load Observed Data:**  \n",
    "    It reads a CSV file called `\"Obs_temp_PT100_t.dat\"` that contains temperature measurements from the sensors.\n",
    "\n",
    "6. **Clean Up the Data:**  \n",
    "    - Makes sure all temperature columns are numbers (not text).\n",
    "    - Makes sure the `\"Time\"` column is a number (seconds).\n",
    "    - Converts the `\"dates\"` column into real date/time objects so we can plot or analyze time series.\n",
    "\n",
    "7. **Show the Data:**  \n",
    "    It displays the first few rows of the cleaned data so you can check if it looks right.\n",
    "\n",
    "8. **Set Up Folders:**  \n",
    "    - It creates three folders to organize results: one for sensitivity analysis, one for outputs, and one for parameters.\n",
    "    - Each folder name includes the station name (e.g., `SENSI_IntD`).\n",
    "\n",
    "9. **Prepare Simulation Folders:**  \n",
    "    The function `prepare_ginette_directories` makes sure all these folders exist in the right place.\n",
    "\n",
    "10. **Change to the Main Directory:**  \n",
    "     The code moves into the main folder where all the simulation files will be stored.\n",
    "\n",
    "11. **Compile the Simulation Code:**  \n",
    "     If the simulation code needs to be compiled (turned into something the computer can run), this line does it.\n",
    "\n",
    "**In short:**  \n",
    "This code loads your temperature data, cleans it up, sets up folders for your results, and gets everything ready to run simulations for the `\"IntD\"` station.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f48b5e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENSI_IntD\n",
      "OUTPUT_IntD\n",
      "PARAMETER_IntD\n",
      "Current working directory: /home/ariviere/Programmes/ginette/application/RIV2D/IntD\n",
      "Directory 'SENSI_IntD' already exists.\n",
      "Directory 'OUTPUT_IntD' already exists.\n",
      "Directory 'PARAMETER_IntD' already exists.\n",
      "ginette exists\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reload the Grid_search module to ensure any recent changes are reflected\n",
    "importlib.reload(Grid_search)\n",
    "\n",
    "# Set the simulation start date (background date for the simulation)\n",
    "date_simul_bg = pd.to_datetime(\"2016/09/19 12:00:00\")\n",
    "\n",
    "# Station name is already defined in the notebook as 'Station'\n",
    "Station = Station\n",
    "\n",
    "# List of sensor names used for temperature measurements\n",
    "sensors = [\"Temp_1\", \"Temp_2\", \"Temp_3\", \"Temp_4\", \"Temp_5\", \"Temp_6\", \"Temp_7\", \"Temp_8\"]\n",
    "\n",
    "# Load observed temperature data from CSV file\n",
    "obs_temp = pd.read_csv(\"Obs_temp_PT100_t.dat\", sep=\",\", header=0)\n",
    "\n",
    "# Convert each sensor column to numeric, coercing errors to NaN\n",
    "for i in range(len(sensors)):\n",
    "    obs_temp[sensors[i]] = pd.to_numeric(obs_temp[sensors[i]], errors='coerce')\n",
    "\n",
    "# Ensure the 'Time' column is numeric (in seconds)\n",
    "obs_temp['Time'] = pd.to_numeric(obs_temp['Time'], errors='coerce')\n",
    "\n",
    "# Convert the 'dates' column to datetime objects for time series analysis\n",
    "obs_temp['dates'] = pd.to_datetime(obs_temp['dates'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Display the first few rows of the loaded and processed data\n",
    "obs_temp.head()\n",
    "\n",
    "\n",
    "# Define subdirectories for storing sensitivity, output, and parameter files\n",
    "subdirectories = ['SENSI', 'OUTPUT', 'PARAMETER']\n",
    "\n",
    "# Append the station name to each subdirectory for organization\n",
    "for i in range(len(subdirectories)):\n",
    "    subdirectories[i] = subdirectories[i] + \"_\" + Station\n",
    "    print(subdirectories[i])\n",
    "\n",
    "# Prepare the Ginette simulation directories (creates folders if needed)\n",
    "prepare_ginette_directories(main_dir, subdirectories=subdirectories)\n",
    "\n",
    "# Change the working directory to the main simulation directory\n",
    "os.chdir(main_dir)\n",
    "\n",
    "# Compile the Ginette source code (if needed for the simulation)\n",
    "compile_ginette_src(dir_ginette)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b02cce4",
   "metadata": {},
   "source": [
    "# PARAMETERS RANGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3855943d",
   "metadata": {},
   "source": [
    "## Using generate_grid_search_table for Grid Search\n",
    "\n",
    "The function generate_grid_search_table helps you create a DataFrame containing all possible combinations of parameter values for the specified zones and parameters. This is useful for systematically exploring parameter spaces in grid search optimization.\n",
    "\n",
    "#### How to Use\n",
    "\n",
    "1. **Define the zones to invert:**  \n",
    "List the zone numbers you want to include in the grid search.\n",
    "```python\n",
    "zones_to_invert = [4, 5]\n",
    "```\n",
    "\n",
    "2. **Specify the parameters to invert:**  \n",
    "List the parameter names (as strings) you want to vary.\n",
    "```python\n",
    "parameters = ['k', 'n']\n",
    "```\n",
    "\n",
    "3. **Set the parameter ranges:**  \n",
    "Use a dictionary where each key is a zone number, and each value is another dictionary mapping parameter names to their ranges.  \n",
    "Each range can be:\n",
    "- A tuple `(min, max, step)` for generating values with `np.arange`\n",
    "- A list of explicit values\n",
    "\n",
    "#### Example:\n",
    "```python\n",
    "param_ranges = {\n",
    "     4: {'k': (-12, -10.5, 2), 'n': (0.01, 0.1, 0.1)},\n",
    "     5: {'k': (-15, -11, 4), 'n': (0.3, 0.8, 0.7)}\n",
    "}\n",
    "```\n",
    "\n",
    "4. **Generate the parameter table:**  \n",
    "Call the function with your zones, parameters, and ranges.\n",
    "```python\n",
    "param_table = generate_grid_search_table(zones_to_invert, parameters, param_ranges)\n",
    "```\n",
    "\n",
    "5. **View the results:**  \n",
    "The resulting `param_table` is a pandas DataFrame. You can display the first few rows:\n",
    "```python\n",
    "print(param_table.head())\n",
    "```\n",
    "\n",
    "### Example Output\n",
    "\n",
    "            |   k4   |   n4   |  k5  |  n5  |\n",
    "            |--------|--------|------|------|\n",
    "            | -12.0  | 0.01   | -15  | 0.3  |\n",
    "            | -12.0  | 0.01   | -15  | 1.0  |\n",
    "            | -12.0  | 0.01   | -11  | 0.3  |\n",
    "            | ...    | ...    | ...  | ...  |\n",
    "\n",
    "This table contains all combinations of the specified parameter values for each zone. Use it to run simulations or analyses for each parameter set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a32ca385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zone 4, Parameter 'k': Values = [-15.  -14.5 -14.  -13.5 -13.  -12.5 -12.  -11.5 -11.  -10.5]\n",
      "Zone 4, Parameter 'n': Values = [0.05 0.15 0.25 0.35 0.45 0.55 0.65 0.75]\n",
      "Zone 4, Parameter 'l': Values = [1. 2. 3. 4. 5. 6. 7. 8.]\n",
      "Zone 5, Parameter 'k': Values = [-15.  -14.5 -14.  -13.5 -13.  -12.5 -12.  -11.5 -11.  -10.5]\n",
      "Zone 5, Parameter 'n': Values = [0.05 0.15 0.25 0.35 0.45 0.55 0.65 0.75]\n",
      "Zone 5, Parameter 'l': Values = [1. 2. 3. 4. 5. 6. 7. 8.]\n",
      "Nombre de simulations : 409600\n",
      "      k4    n4   l4    k5    n5   l5\n",
      "0  -15.0  0.05  1.0 -15.0  0.05  1.0\n",
      "1  -15.0  0.05  1.0 -15.0  0.05  2.0\n",
      "2  -15.0  0.05  1.0 -15.0  0.05  3.0\n",
      "3  -15.0  0.05  1.0 -15.0  0.05  4.0\n",
      "4  -15.0  0.05  1.0 -15.0  0.05  5.0\n",
      "..   ...   ...  ...   ...   ...  ...\n",
      "95 -15.0  0.05  1.0 -14.5  0.35  8.0\n",
      "96 -15.0  0.05  1.0 -14.5  0.45  1.0\n",
      "97 -15.0  0.05  1.0 -14.5  0.45  2.0\n",
      "98 -15.0  0.05  1.0 -14.5  0.45  3.0\n",
      "99 -15.0  0.05  1.0 -14.5  0.45  4.0\n",
      "\n",
      "[100 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "simul_todo = range(1, 2)\n",
    "# List of parameter names for each zone (used in parameter tables)\n",
    "param_struct = ['zone', 'k', 'n', 'l', 'cpm', 'r']\n",
    "\n",
    "# Set the measurement uncertainty (standard deviation of temperature measurements)\n",
    "sigma = 0.2\n",
    "\n",
    "# Define the zones where parameters will be inverted (calibrated)\n",
    "zones_to_invert = [4, 5]\n",
    "\n",
    "# Define which parameters will be inverted for each zone\n",
    "parameters_to_invert = ['k', 'n','l']\n",
    "# Define the range (min, max, step) for each parameter in each zone\n",
    "param_ranges = {\n",
    "    4: {'k': (-15, -10.5, 0.5), 'n': (0.05, 0.75, 0.1),'l': (1, 8, 1)},\n",
    "    5: {'k': (-15, -10.5, 0.5), 'n': (0.05, 0.75, 0.1), 'l': (1, 8, 1)}\n",
    "}\n",
    "\n",
    "# Generate a table (DataFrame) with all combinations of parameters for the grid search\n",
    "param_table = generate_grid_search_table(zones_to_invert, parameters_to_invert, param_ranges)\n",
    "\n",
    "# Print the total number of simulations that will be run\n",
    "print(f\"Nombre de simulations : {len(param_table)}\")\n",
    "\n",
    "\n",
    "# Afficher les premières lignes du tableau\n",
    "print(param_table.head(100))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create input_inversion.txt file to have all parameter needed for the inversion i.e date_simul_bg, sigma, zones_to_invert, parameters_to_invert, param_ranges\n",
    "with open(\"input_inversion.txt\", \"w\") as f:\n",
    "    f.write(f\"date_simul_bg: {date_simul_bg.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"Station: {Station}\\n\")\n",
    "    f.write(f\"param_struct: {', '.join([repr(x) for x in param_struct])}\\n\")\n",
    "    f.write(f\"sensors: {', '.join([repr(x) for x in sensors])}\\n\")\n",
    "    f.write(f\"sigma: {sigma}\\n\")\n",
    "    f.write(f\"zones_to_invert: {', '.join(str(z) for z in zones_to_invert)}\\n\")\n",
    "    f.write(f\"parameters_to_invert: {', '.join([repr(x) for x in parameters_to_invert])}\\n\")\n",
    "    f.write(f\"simul_todo: {simul_todo.start}, {simul_todo.stop}\\n\")\n",
    "    f.write(f\"path_simul: {main_dir}\\n\")\n",
    "    f.write(f\"dir_ginette: {dir_ginette}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26455fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove IntD_grid_search.py\n",
    "name_file = Station + \"_grid_search.py\"\n",
    "os.remove(name_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53c4f61d",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting IntD_grid_search.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile  IntD_grid_search.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "# read the input_inversion.txt file#%%writefile IntD_grid_search.py\n",
    "with open(\"input_inversion.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Helper to parse a line of the form \"key: value\"\n",
    "def parse_line(line):\n",
    "    key, value = line.strip().split(\":\", 1)\n",
    "    return key.strip(), value.strip()\n",
    "\n",
    "parsed = dict(parse_line(line) for line in lines)\n",
    "\n",
    "date_simul_bg = parsed[\"date_simul_bg\"]\n",
    "Station = parsed[\"Station\"]\n",
    "# Read param_struct from the parsed input and convert to list\n",
    "param_struct = [x.strip(\" '\") for x in parsed[\"param_struct\"].split(\",\")]\n",
    "sensors = [x.strip(\" '\") for x in parsed[\"sensors\"].split(\",\")]\n",
    "sigma = float(parsed[\"sigma\"])\n",
    "zones_to_invert = [int(z) for z in parsed[\"zones_to_invert\"].strip(\"[]\").split(\",\")]\n",
    "parameters_to_invert = [x.strip(\" '\") for x in parsed[\"parameters_to_invert\"].split(\",\")]\n",
    "simul_todo_range = parsed[\"simul_todo\"].split(\",\")\n",
    "simul_todo = range(int(simul_todo_range[0]), int(simul_todo_range[1]))\n",
    "main_dir = parsed[\"path_simul\"]\n",
    "dir_ginette = parsed[\"dir_ginette\"]\n",
    "\n",
    "os.chdir(main_dir)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "# Ajouter le chemin du dossier src au PYTHONPATH\n",
    "import importlib\n",
    "sys.path.append(dir_ginette)  # Ajouter le dossier parent de src\n",
    "\n",
    "# use __init__.py to import all functions/ in src/src_gmsh and src/src_pythont\n",
    "# insure \n",
    "from src.src_gmsh import mesh_generator\n",
    "from src.src_python import Init_folders\n",
    "from src.src_python import Direct_model\n",
    "from src.src_python import Read_obs\n",
    "from src.src_python import Plot\n",
    "from src.src_python import stat_critere\n",
    "from src.src_python import Grid_search\n",
    "\n",
    "# Import all functions/classes from the relevant modules\n",
    "from src.src_gmsh.mesh_generator import *\n",
    "from src.src_python.Init_folders import *\n",
    "from src.src_python.Direct_model import *\n",
    "from src.src_python.Read_obs import *\n",
    "from src.src_python.Plot import *\n",
    "from src.src_python.stat_critere import *\n",
    "from src.src_python.Grid_search import *\n",
    "import importlib\n",
    "\n",
    "\n",
    "importlib.reload(Init_folders)\n",
    "importlib.reload(Direct_model)\n",
    "importlib.reload(Grid_search)\n",
    "from src.src_python.Grid_search import *\n",
    "from src.src_python import Grid_search\n",
    "importlib.reload(Grid_search)\n",
    "\n",
    "# Convert the date_simul_bg to datetime\n",
    "date_simul_bg = pd.to_datetime(date_simul_bg, format='%Y-%m-%d %H:%M:%S')\n",
    "print(f\"date_simul_bg: {date_simul_bg}\")\n",
    "print(f\"Station: {Station}\")\n",
    "print(f\"param_struct: {param_struct}\")\n",
    "print(f\"sensors: {sensors}\")\n",
    "print(f\"sigma: {sigma}\")\n",
    "print(f\"zones_to_invert: {zones_to_invert}\")\n",
    "print(f\"parameters_to_invert: {parameters_to_invert}\")\n",
    "print(f\"simul_todo: {simul_todo}\")\n",
    "print(f\"path_simul: {main_dir}\")\n",
    "print(f\"dir_ginette: {dir_ginette}\")\n",
    "\n",
    "\n",
    "# read the param_table.txt file\n",
    "param_table = pd.read_csv(\"param_table.txt\", sep=\",\", header=0)\n",
    "param_table['index_sim'] = param_table.index + 1\n",
    "header_save_param = param_table.columns\n",
    "\n",
    "# Table of simulated parameters\n",
    "# param_table = pd.DataFrame(columns=header_save_param)\n",
    "param_table_simul = pd.DataFrame(columns=header_save_param)\n",
    "\n",
    "# make a loop to run each index_sim in simul_todo\n",
    "for id_sim in simul_todo:\n",
    "    print(f\"Simulation {id_sim}\")\n",
    "    param_table_id_sim = run_one_simulation_2D(\n",
    "        Station, main_dir, date_simul_bg, sensors,\n",
    "        param_table, id_sim, param_struct, zones_to_invert,\n",
    "        parameters_to_invert, param_table_simul, dir_ginette\n",
    "    )\n",
    "\n",
    "param_table_simul = pd.concat([param_table_simul, param_table_id_sim], ignore_index=True)\n",
    "\n",
    "\n",
    "param_table_simul.to_csv(\"PARAMETER_\" + Station + \"/\"+ \"S_parmeters_simul.dat\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
